# Execution time: 54.57 seconds
# Model used: gpt-5-mini

# Issues / Assumptions:
# - ConversableAgent (a concrete agent class used in the source code) is not present in the ontology; LLMAgent is used to represent these instances.
# - The ontology lacks a dedicated property for "human_input_mode" or for "termination_condition"; these are represented using Config individuals (hasAgentConfig -> Config -> configKey/configValue).
# - The source code contains executable lambda expressions (is_termination_msg). Functionality and executable semantics cannot be represented natively in the ontology; the exact lambda text is preserved as literal configValue strings.
# - The content and structure of llm_config is not provided in the notebook excerpt; it is referenced as an external variable. We create Config entries preserving the reference but cannot expand its internal fields.
# - The transient message stream / conversation state and per-message objects are not modeled (ontology lacks message class). We only model persistent structural elements (agents, prompts, configs, language model).
# - No explicit Task, Tool, WorkflowStep, or WorkflowPattern objects are present in the source excerpt; therefore only agents, prompts, configs and a language model are instantiated.
# - If richer modeling of interactive conversation flow, termination conditions as first-class properties, or explicit "ConversableAgent" semantics are required, new properties/classes would be needed (not added here per instructions).

@prefix : <http://www.w3id.org/agentic-ai/onto#> .
@prefix pp: <http://purl.org/net/p-plan#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix xml: <http://www.w3.org/XML/1998/namespace> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix beam: <http://w3id.org/beam/core#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@base <http://www.w3id.org/agentic-ai/onto#> .

#################################################################
# Instances extracted from L1_Multi-Agent_Conversation_and_Stand-up_Comedy.ipynb
#################################################################

# Language model (referenced by variable llm_config in the notebook)
:LLM_Default rdf:type :LanguageModel ;
    <http://purl.org/dc/terms/title> "llm_config language model (unspecified)" ;
    <http://purl.org/dc/terms/description> "Language model referenced by variable llm_config in the notebook; the notebook excerpt does not provide its internal configuration or parameters." .

# Agent: cathy (ConversableAgent in the code -> represented as LLMAgent)
:CathyAgent rdf:type :LLMAgent ;
    :agentID "cathy" ;
    :agentRole "stand-up comedian" ;
    :agentPrompt :CathyPrompt ;
    :useLanguageModel :LLM_Default ;
    :hasAgentConfig :CathyConfig_human_input_mode , :CathyConfig_is_termination_msg , :CathyConfig_llm_config ;
    :interactsWith :JoeAgent .

# Agent: joe (ConversableAgent in the code -> represented as LLMAgent)
:JoeAgent rdf:type :LLMAgent ;
    :agentID "joe" ;
    :agentRole "stand-up comedian" ;
    :agentPrompt :JoePrompt ;
    :useLanguageModel :LLM_Default ;
    :hasAgentConfig :JoeConfig_human_input_mode , :JoeConfig_is_termination_msg , :JoeConfig_llm_config ;
    :interactsWith :CathyAgent .

# Prompts: system messages passed to the agents at creation
:CathyPrompt rdf:type :Prompt ;
    :promptInstruction "Your name is Cathy and you are a stand-up comedian. When you're ready to end the conversation, say 'I gotta go'." ;
    :promptContext "System message as provided at ConversableAgent creation in the notebook." ;
    :promptOutputIndicator "When you're ready to end the conversation, say 'I gotta go'." .

:JoePrompt rdf:type :Prompt ;
    :promptInstruction "Your name is Joe and you are a stand-up comedian. When you're ready to end the conversation, say 'I gotta go'." ;
    :promptContext "System message as provided at ConversableAgent creation in the notebook." ;
    :promptOutputIndicator "When you're ready to end the conversation, say 'I gotta go'." .

# Configs for Cathy
:CathyConfig_human_input_mode rdf:type :Config ;
    :configKey "human_input_mode" ;
    :configValue "NEVER" .

:CathyConfig_is_termination_msg rdf:type :Config ;
    :configKey "is_termination_msg" ;
    :configValue """lambda msg: "I gotta go" in msg["content"]""" .

:CathyConfig_llm_config rdf:type :Config ;
    :configKey "llm_config" ;
    :configValue "llm_config (external variable referenced in the notebook; details not provided in excerpt)" .

# Configs for Joe
:JoeConfig_human_input_mode rdf:type :Config ;
    :configKey "human_input_mode" ;
    :configValue "NEVER" .

:JoeConfig_is_termination_msg rdf:type :Config ;
    :configKey "is_termination_msg" ;
    :configValue """lambda msg: "I gotta go" in msg["content"] or "Goodbye" in msg["content"]""" .

:JoeConfig_llm_config rdf:type :Config ;
    :configKey "llm_config" ;
    :configValue "llm_config (external variable referenced in the notebook; details not provided in excerpt)" .

#################################################################
# Notes on semantic mapping decisions (kept out of ontology per instructions)
#################################################################
# - The notebook constructs ConversableAgent objects with parameters: name, system_message, llm_config,
#   human_input_mode, and is_termination_msg (a lambda). ConversableAgent is represented using :LLMAgent
#   and the parameters are captured using :agentID, :agentPrompt, :useLanguageModel, and one or more :Config
#   individuals linked via :hasAgentConfig.
# - The executable lambda expressions are preserved as string literals under Config.configValue for later
#   interpretation by a reconstructing system.
# - The interactive message stream, per-message objects, timing, or runtime conversation control are not
#   modeled because the ontology does not define message classes or conversational session constructs.
# - The two agents are linked with :interactsWith to denote they converse with each other in the notebook.